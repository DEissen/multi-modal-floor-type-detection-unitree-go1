{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# file for easily testing code snippets during development\n",
    "# TODO: remove file once first release is done\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom imports\n",
    "from FTDDataset.FTDDataset import FloorTypeDetectionDataset, FTDD_Crop, FTDD_Normalize, FTDD_Rescale, FTDD_ToTensor\n",
    "from unimodal_models.LeNet import LeNet\n",
    "from train import Trainer\n",
    "from eval import evaluate\n",
    "from custom_utils.custom_utils import gen_run_dir, set_loggers\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\Dominik\\Downloads\\FTDD_0.1\"\n",
    "mapping_filename = \"label_mapping_binary.json\"\n",
    "preprocessing_config_filename = \"preprocessing_config.json\"\n",
    "\n",
    "# list of sensors to use\n",
    "# sensors = [\"accelerometer\", \"BellyCamRight\", \"BellyCamLeft\", \"ChinCamLeft\",\n",
    "#            \"ChinCamRight\", \"HeadCamLeft\", \"HeadCamRight\", \"LeftCamLeft\", \"LeftCamRight\", \"RightCamLeft\", \"RightCamRight\"]\n",
    "sensors = [\"BellyCamRight\"]\n",
    "# sensors = ['accelerometer', 'BellyCamLeft', 'BellyCamRight', 'bodyHeight', 'ChinCamLeft', 'ChinCamRight', 'footForce', 'footRaiseHeight', 'gyroscope',\n",
    "#            'HeadCamLeft', 'HeadCamRight', 'LeftCamLeft', 'LeftCamRight', 'mode', 'RightCamLeft', 'RightCamRight', 'temperature', 'velocity', 'yawSpeed']\n",
    "\n",
    "# config for training\n",
    "train_config = {\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 0.001,\n",
    "    \"momentum\": 0.9\n",
    "}\n",
    "\n",
    "# create list of transformations to perform (data preprocessing + failure case creation)\n",
    "transformations_list = []\n",
    "transformations_list.append(FTDD_Crop(preprocessing_config_filename))\n",
    "transformations_list.append(FTDD_Rescale(preprocessing_config_filename))\n",
    "transformations_list.append(FTDD_Normalize(preprocessing_config_filename))\n",
    "transformations_list.append(FTDD_ToTensor())\n",
    "composed_transforms = transforms.Compose(transformations_list)\n",
    "\n",
    "# create dataset\n",
    "transformed_dataset = FloorTypeDetectionDataset(\n",
    "    dataset_path, sensors, mapping_filename, transform=composed_transforms)\n",
    "\n",
    "# split in train and test dataset\n",
    "train_size = int(0.8 * len(transformed_dataset))\n",
    "test_size = len(transformed_dataset) - train_size\n",
    "ds_train, ds_test = torch.utils.data.random_split(\n",
    "    transformed_dataset, [train_size, test_size])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
